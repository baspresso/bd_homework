{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL8iqhwcE_R0",
        "outputId": "5fb16e50-611f-471d-ba66-3c00267693b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=ad389f5ac6edb8d25b6ca54e01a124481f293c05c4a3a9d66481b02a7017bc5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai1zmcE8EwSi",
        "outputId": "75762a46-4cd8-4e81-c4c1-51ae0a4a36e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+-----------------------------+-------+-------------+--------+---------+\n",
            "|        dt|AverageTemperature|AverageTemperatureUncertainty|   City|      Country|Latitude|Longitude|\n",
            "+----------+------------------+-----------------------------+-------+-------------+--------+---------+\n",
            "|1849-01-01|            26.704|                        1.435|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
            "|1849-02-01|            27.434|                        1.362|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
            "|1849-03-01|            28.101|                        1.612|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
            "|1849-04-01|             26.14|           1.3869999999999998|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
            "|1849-05-01|            25.427|                          1.2|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
            "|1849-06-01|            24.844|                        1.402|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
            "|1849-07-01|24.058000000000003|                        1.254|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
            "|1849-08-01|            23.576|                        1.265|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
            "|1849-09-01|            23.662|                        1.226|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
            "|1849-10-01|            25.263|                        1.175|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|\n",
            "+----------+------------------+-----------------------------+-------+-------------+--------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"PySpark\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "with open(\"GlobalLandTemperaturesByMajorCity.csv\") as f:\n",
        "    pandas_df = pd.read_csv(f)\n",
        "    df = spark.createDataFrame(pandas_df)\n",
        "\n",
        "df.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В последующих заданиях будут учитываться данные начиная с 01.01.1950. Для этого создайте новый DataFrame, в котором удалены все строки до 01.01.1950. Используйте созданный DataFrame в последующих заданиях."
      ],
      "metadata": {
        "id": "CauhzZ2eGey3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "df = df.withColumn(\"dt\", col(\"dt\").cast(\"date\"))\n",
        "df = df.filter(col(\"dt\") >= '1950-01-01')\n",
        "df = df.filter(col(\"AverageTemperature\").isNotNull())\n",
        "df = df.dropna(subset=[\"AverageTemperature\"])\n",
        "\n",
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzL6GAtoGhqO",
        "outputId": "e3812513-97b3-4e34-987b-9e1d3c6dd81f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+-----------------------------+-------+-------------+--------+---------+----+-----+\n",
            "|        dt|AverageTemperature|AverageTemperatureUncertainty|   City|      Country|Latitude|Longitude|Year|Month|\n",
            "+----------+------------------+-----------------------------+-------+-------------+--------+---------+----+-----+\n",
            "|1950-01-01|26.773000000000003|                        0.239|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|1950|    1|\n",
            "|1950-02-01|            27.527|                        0.348|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|1950|    2|\n",
            "|1950-03-01|            28.344|                        0.431|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|1950|    3|\n",
            "|1950-04-01|             27.83|                        0.467|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|1950|    4|\n",
            "|1950-05-01|            26.896|                        0.248|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|1950|    5|\n",
            "|1950-06-01|            25.454|                        0.209|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|1950|    6|\n",
            "|1950-07-01|            24.878|                        0.403|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|1950|    7|\n",
            "|1950-08-01|            23.734|                        0.314|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|1950|    8|\n",
            "|1950-09-01|            24.253|                        0.257|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|1950|    9|\n",
            "|1950-10-01|            25.266|                        0.191|Abidjan|Côte D'Ivoire|   5.63N|    3.23W|1950|   10|\n",
            "+----------+------------------+-----------------------------+-------+-------------+--------+---------+----+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найдите город, для которого выборочная дисперсия температур на приведенных данных максимальна."
      ],
      "metadata": {
        "id": "8H8xJtKwG_Y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import variance, desc\n",
        "\n",
        "variance_df = df.groupBy(\"City\").agg(variance(\"AverageTemperature\").alias(\"TemperatureVariance\"))\n",
        "max_variance_city = variance_df.orderBy(desc(\"TemperatureVariance\")).first()\n",
        "\n",
        "max_variance_city"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PCBAE3mQh_1",
        "outputId": "f19a689e-ef3a-4ace-cdbf-39b2b95e09b9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(City='Harbin', TemperatureVariance=218.898615951821)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посчитайте данные по среднегодовой температуре в Санкт-Петербурге. Определите года, в которых средняя температура была выше, чем в предыдущем и последующем году."
      ],
      "metadata": {
        "id": "wmGYbIL3HpkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import year, avg\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import lag, lead, col\n",
        "\n",
        "spb_data = df.filter(col(\"City\") == \"Saint Petersburg\")\n",
        "spb_data = spb_data.withColumn(\"Year\", year(col(\"dt\")))\n",
        "\n",
        "# Cреднегодовая температура для каждого года\n",
        "avg_yearly_temp = spb_data.groupBy(\"Year\").agg(avg(\"AverageTemperature\").alias(\"AvgTemp\")).orderBy(\"Year\")\n",
        "\n",
        "window_spec = Window.orderBy(\"Year\")\n",
        "avg_yearly_temp = avg_yearly_temp.withColumn(\"PrevYearTemp\", lag(\"AvgTemp\").over(window_spec))\n",
        "avg_yearly_temp = avg_yearly_temp.withColumn(\"NextYearTemp\", lead(\"AvgTemp\").over(window_spec))\n",
        "\n",
        "years_with_high_temps = avg_yearly_temp.filter(\n",
        "    (col(\"AvgTemp\") > col(\"PrevYearTemp\")) & (col(\"AvgTemp\") > col(\"NextYearTemp\"))\n",
        ").select(\"Year\")\n",
        "\n",
        "years_with_high_temps.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjNss57QHlSR",
        "outputId": "7bc9363c-aead-4b06-f570-b19a12257fc7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+\n",
            "|Year|\n",
            "+----+\n",
            "|1953|\n",
            "|1957|\n",
            "|1959|\n",
            "|1961|\n",
            "|1964|\n",
            "|1967|\n",
            "|1972|\n",
            "|1975|\n",
            "|1977|\n",
            "|1979|\n",
            "|1983|\n",
            "|1986|\n",
            "|1989|\n",
            "|1992|\n",
            "|1995|\n",
            "|1997|\n",
            "|2000|\n",
            "|2002|\n",
            "|2005|\n",
            "|2008|\n",
            "+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найдите города, для которых:"
      ],
      "metadata": {
        "id": "pa17NP-2IXMI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Разница между максимальным и минимальным значением среднегодовой температуры в выборке максимальна."
      ],
      "metadata": {
        "id": "1buTimU3Ig8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import min, max\n",
        "\n",
        "df = df.withColumn(\"Year\", year(col(\"dt\")))\n",
        "avg_yearly_temp_city = df.groupBy(\"City\", \"Year\").agg(avg(\"AverageTemperature\").alias(\"AvgTemp\"))\n",
        "temp_diff_city = avg_yearly_temp_city.groupBy(\"City\").agg(\n",
        "    (max(\"AvgTemp\") - min(\"AvgTemp\")).alias(\"TempDiff\")\n",
        ")\n",
        "max_temp_diff_city = temp_diff_city.orderBy(col(\"TempDiff\").desc()).first()\n",
        "\n",
        "max_temp_diff_city\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAwkWyFVIgUA",
        "outputId": "fc43e34b-eefe-4894-9535-0b7364d2e94f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(City='Mashhad', TempDiff=5.250000000000002)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Самая большая средняя разница между средней температурой января и средней температурой июля."
      ],
      "metadata": {
        "id": "jKEB5iTuJBz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import month, countDistinct\n",
        "\n",
        "jan_jul_data = df.filter((month(col(\"dt\")) == 1) | (month(col(\"dt\")) == 7))\n",
        "\n",
        "jan_jul_avg_temp = jan_jul_data.groupBy(\"City\", \"Year\", month(col(\"dt\")).alias(\"Month\")).agg(avg(\"AverageTemperature\").alias(\"AvgTemp\"))\n",
        "jan_avg_temp = jan_jul_avg_temp.filter(col(\"Month\") == 1).select(\"City\", \"Year\", col(\"AvgTemp\").alias(\"JanTemp\"))\n",
        "jul_avg_temp = jan_jul_avg_temp.filter(col(\"Month\") == 7).select(\"City\", \"Year\", col(\"AvgTemp\").alias(\"JulTemp\"))\n",
        "jan_jul_avg_temp_diff = jan_avg_temp.join(jul_avg_temp, on=[\"City\", \"Year\"])\n",
        "jan_jul_avg_temp_diff = jan_jul_avg_temp_diff.withColumn(\"TempDiff\", col(\"JulTemp\") - col(\"JanTemp\"))\n",
        "avg_temp_diff_city = jan_jul_avg_temp_diff.groupBy(\"City\").agg(avg(\"TempDiff\").alias(\"AvgTempDiff\"))\n",
        "max_avg_temp_diff_city = avg_temp_diff_city.orderBy(col(\"AvgTempDiff\").desc()).first()\n",
        "\n",
        "max_avg_temp_diff_city\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJKpmdLNJB_W",
        "outputId": "6d4c2126-5420-4d6a-8720-14f88c6d055c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(City='Harbin', AvgTempDiff=41.99271875000001)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Наибольшее среднее количество месяцев с отрицательной температурой в году"
      ],
      "metadata": {
        "id": "Id5DXBL6JRn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\"Month\", month(col(\"dt\")))\n",
        "\n",
        "negative_temp_months = df.filter(col(\"AverageTemperature\") < 0).groupBy(\"City\", \"Year\").agg(countDistinct(\"Month\").alias(\"NegativeMonths\"))\n",
        "avg_negative_months_city = negative_temp_months.groupBy(\"City\").agg(avg(\"NegativeMonths\").alias(\"AvgNegativeMonths\"))\n",
        "max_avg_negative_months_city = avg_negative_months_city.orderBy(col(\"AvgNegativeMonths\").desc()).first()\n",
        "\n",
        "max_avg_negative_months_city\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EQM00-cJRzz",
        "outputId": "f8b70518-a724-4076-8088-c13693df42b1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(City='Harbin', AvgNegativeMonths=4.90625)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXVr77bxXBcI",
        "outputId": "c07c351a-7162-4c5f-8cbe-383f0b532921"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=4ac7d52feb7bd5deb47012c266b4b8bffdb7e0d856abe66e9202ceabbd2900b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import explode, split, length, col, sum, count, regexp_extract"
      ],
      "metadata": {
        "id": "npjO_J0cVvG6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Программа, которая находит самое длинное слово."
      ],
      "metadata": {
        "id": "8Vzzkro1RmpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"WikiAnalysis\").getOrCreate()\n",
        "\n",
        "df = spark.read.option(\"delimiter\", \"\\t\").csv(\"wiki.txt\").toDF(\"url\", \"title\", \"text\")\n",
        "\n",
        "words_df = df.select(explode(split(col(\"text\"), \"\\\\s+\")).alias(\"word\"))\n",
        "longest_word = words_df.withColumn(\"length\", length(col(\"word\"))) \\\n",
        "                       .orderBy(col(\"length\").desc()) \\\n",
        "                       .first()\n",
        "\n",
        "print(f\"Самое длинное слово: {longest_word['word']}\")\n",
        "\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPVHNwaGV4L4",
        "outputId": "858ea893-0aab-41ae-c314-6841ad988302"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Самое длинное слово: [https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%85%D0%B0%D0%BD%D0%B8%D0%BA%D0%B0_%D0%BA%D0%BE%D0%BD%D1%82%D0%B0%D0%BA%D1%82%D0%BD%D0%BE%D0%B3%D0%BE_%D0%B2%D0%B7%D0%B0%D0%B8%D0%BC%D0%BE%D0%B4%D0%B5%D0%B9%D1%81%D1%82%D0%B2%D0%B8%D1%8F#.D0.AD.D0.BD.D0.B5.D1.80.D0.B3.D0.B8.D1.8F_.D0.BF.D1.80.D0.B8_.D1.83.D0.BF.D1.80.D1.83.D0.B3.D0.BE.D0.BC_.D0.BA.D0.BE.D0.BD.D1.82.D0.B0.D0.BA.D1.82.D0.B5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Программа, которая находит среднюю длину слов."
      ],
      "metadata": {
        "id": "cD4rHZ30SL-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"WikiAnalysis\").getOrCreate()\n",
        "\n",
        "df = spark.read.option(\"delimiter\", \"\\t\").csv(\"wiki.txt\").toDF(\"url\", \"title\", \"text\")\n",
        "\n",
        "words_df = df.select(explode(split(col(\"text\"), \"\\\\s+\")).alias(\"word\"))\n",
        "average_length = words_df.withColumn(\"length\", length(col(\"word\"))) \\\n",
        "                         .selectExpr(\"avg(length) as avg_length\") \\\n",
        "                         .first()\n",
        "\n",
        "print(f\"Средняя длина слов: {average_length['avg_length']}\")\n",
        "\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzn33XLQV9CK",
        "outputId": "f330902b-3c58-4a9b-91da-25b1027568e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Средняя длина слов: 6.53168068423701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Программа, которая находит самое частоупотребляемое слово, состоящее из латинских букв."
      ],
      "metadata": {
        "id": "uL-xlOMjShYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"WikiAnalysis\").getOrCreate()\n",
        "\n",
        "df = spark.read.option(\"delimiter\", \"\\t\").csv(\"wiki.txt\").toDF(\"url\", \"title\", \"text\")\n",
        "\n",
        "words_df = df.select(explode(split(col(\"text\"), \"\\\\s+\")).alias(\"word\"))\n",
        "latin_words_df = words_df.withColumn(\"latin_word\", regexp_extract(col(\"word\"), \"^[a-zA-Z]+$\", 0)) \\\n",
        "                         .filter(col(\"latin_word\") != \"\")\n",
        "most_common_word = latin_words_df.groupBy(\"latin_word\") \\\n",
        "                                 .count() \\\n",
        "                                 .orderBy(col(\"count\").desc()) \\\n",
        "                                 .first()\n",
        "\n",
        "print(f\"Самое частоупотребляемое слово: {most_common_word['latin_word']}\")\n",
        "\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4x7QU3-WDe1",
        "outputId": "85afe808-9861-49b2-9dc1-68f782543fd3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Самое частоупотребляемое слово: XX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Все слова, которые более чем в половине случаев начинаются с большой буквы и встречаются больше 10 раз"
      ],
      "metadata": {
        "id": "Vtx0197TSnXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"WikiAnalysis\").getOrCreate()\n",
        "df = spark.read.option(\"delimiter\", \"\\t\").csv(\"wiki.txt\").toDF(\"url\", \"title\", \"text\")\n",
        "\n",
        "words_df = df.select(explode(split(col(\"text\"), \"\\\\s+\")).alias(\"word\"))\n",
        "capitalized_words_df = words_df.withColumn(\"is_capitalized\", col(\"word\").substr(1, 1).rlike(\"[A-ZА-Я]\"))\n",
        "grouped_words_df = capitalized_words_df.groupBy(\"word\") \\\n",
        "                                       .agg(sum(col(\"is_capitalized\").cast(\"int\")).alias(\"capitalized_count\"),\n",
        "                                            count(\"word\").alias(\"total_count\"))\n",
        "\n",
        "result_df = grouped_words_df.filter((col(\"capitalized_count\") > col(\"total_count\") / 2) &\n",
        "                                    (col(\"total_count\") > 10))\n",
        "\n",
        "result_df.show(truncate=False)\n",
        "\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjcW5qm6WPuU",
        "outputId": "d1be4c6b-3634-4952-cd36-4b707fa58814"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------------+-----------+\n",
            "|word             |capitalized_count|total_count|\n",
            "+-----------------+-----------------+-----------+\n",
            "|Население —      |169              |169        |\n",
            "|Всемирного       |186              |186        |\n",
            "|XVII             |955              |955        |\n",
            "|Дона,            |24               |24         |\n",
            "|Ниже             |231              |231        |\n",
            "|Принцип          |106              |106        |\n",
            "|Николаевский     |14               |14         |\n",
            "|Демократическая  |65               |65         |\n",
            "|Северо-Восточного|14               |14         |\n",
            "|Каспийское       |42               |42         |\n",
            "|Подобная         |61               |61         |\n",
            "|Ярославом        |11               |11         |\n",
            "|Педру            |36               |36         |\n",
            "|Новгорода —      |11               |11         |\n",
            "|Русском          |52               |52         |\n",
            "|Медицинский      |19               |19         |\n",
            "|Ассамблея        |48               |48         |\n",
            "|Инициатором      |22               |22         |\n",
            "|Китае            |211              |211        |\n",
            "|Рака             |14               |14         |\n",
            "+-----------------+-----------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Программа, которая с помощью статистики определяет устойчивые сокращения вида пр., др., .."
      ],
      "metadata": {
        "id": "36CWrj4ATQW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"AbbreviationAnalysis\").getOrCreate()\n",
        "\n",
        "df = spark.read.option(\"delimiter\", \"\\t\").csv(\"wiki.txt\").toDF(\"url\", \"title\", \"text\")\n",
        "\n",
        "words_df = df.select(explode(split(col(\"text\"), \"\\\\s+\")).alias(\"word\"))\n",
        "abbreviations_df = words_df.withColumn(\"abbreviation\", regexp_extract(col(\"word\"), r\"\\b[a-zA-Zа-яА-Я]+\\.\\b\", 0)) \\\n",
        "                           .filter(col(\"abbreviation\") != \"\")\n",
        "\n",
        "abbreviation_counts = abbreviations_df.groupBy(\"abbreviation\") \\\n",
        "                                      .agg(count(\"abbreviation\").alias(\"count\")) \\\n",
        "                                      .orderBy(col(\"count\").desc())\n",
        "abbreviation_counts.show(truncate=False)\n",
        "\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3c3wJb-TSUl",
        "outputId": "7f6bdf3b-65fb-43ed-b518-bc6bc1581469"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+\n",
            "|abbreviation|count|\n",
            "+------------+-----+\n",
            "|т.          |340  |\n",
            "|А.          |203  |\n",
            "|www.        |173  |\n",
            "|В.          |140  |\n",
            "|н.          |108  |\n",
            "|М.          |100  |\n",
            "|г.          |89   |\n",
            "|тыс.        |84   |\n",
            "|С.          |74   |\n",
            "|Mail.       |70   |\n",
            "|Н.          |63   |\n",
            "|млн.        |60   |\n",
            "|кв.         |59   |\n",
            "|с.          |53   |\n",
            "|OpenOffice. |53   |\n",
            "|ст.         |50   |\n",
            "|И.          |50   |\n",
            "|л.          |47   |\n",
            "|П.          |46   |\n",
            "|Ф.          |45   |\n",
            "+------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найти устойчивые сокращения вида т.п., н.э."
      ],
      "metadata": {
        "id": "30_6LJrhUrh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"AbbreviationAnalysis\").getOrCreate()\n",
        "\n",
        "df = spark.read.option(\"delimiter\", \"\\t\").csv(\"wiki.txt\").toDF(\"url\", \"title\", \"text\")\n",
        "\n",
        "words_df = df.select(explode(split(col(\"text\"), \"\\\\s+\")).alias(\"word\"))\n",
        "compound_abbreviations_df = words_df.withColumn(\"compound_abbreviation\", regexp_extract(col(\"word\"), r\"\\b[a-zA-Zа-яА-Я]+\\.[a-zA-Zа-яА-Я]+\\.\\b\", 0)) \\\n",
        "                                    .filter(col(\"compound_abbreviation\") != \"\")\n",
        "\n",
        "compound_abbreviation_counts = compound_abbreviations_df.groupBy(\"compound_abbreviation\") \\\n",
        "                                                       .agg(count(\"compound_abbreviation\").alias(\"count\")) \\\n",
        "                                                       .orderBy(col(\"count\").desc())\n",
        "\n",
        "compound_abbreviation_counts.show(truncate=False)\n",
        "\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xvpWxvyUvD2",
        "outputId": "888d6c6c-b2e1-4965-a824-a5c9357d9bb5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+-----+\n",
            "|compound_abbreviation|count|\n",
            "+---------------------+-----+\n",
            "|э.д.                 |11   |\n",
            "|R.E.                 |10   |\n",
            "|тыс.кв.              |9    |\n",
            "|ru.wikipedia.        |8    |\n",
            "|и.т.                 |8    |\n",
            "|А.М.                 |6    |\n",
            "|д.м.                 |5    |\n",
            "|д.и.                 |5    |\n",
            "|Q.E.                 |5    |\n",
            "|www.youtube.         |4    |\n",
            "|www.iecat.           |4    |\n",
            "|а.е.                 |4    |\n",
            "|U.S.                 |4    |\n",
            "|S.T.                 |4    |\n",
            "|M.D.                 |4    |\n",
            "|magazines.russ.      |3    |\n",
            "|web.archive.         |3    |\n",
            "|л.ед.                |3    |\n",
            "|en.wikipedia.        |3    |\n",
            "|www.bookcrossing.    |3    |\n",
            "+---------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}